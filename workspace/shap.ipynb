{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import shap\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from janome.tokenizer import Tokenizer\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "from pyknp import KNP\n",
    "import pyknp\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "#from __future__ import unicode_literals # It is not necessary when you use python3.\n",
    "import spacy\n",
    "from pyknp import Juman\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "MIN_LEN=20\n",
    "MAX_LEN=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import shap\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 375/375 [00:00<00:00, 135kB/s]\n",
      "Downloading config.json: 100%|██████████| 3.88k/3.88k [00:00<00:00, 845kB/s]\n",
      "Downloading spiece.model: 100%|██████████| 4.11M/4.11M [00:01<00:00, 3.70MB/s]\n",
      "Downloading special_tokens_map.json: 100%|██████████| 996/996 [00:00<00:00, 657kB/s]\n",
      "The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.17G/2.17G [03:13<00:00, 12.0MB/s] \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "現在のセルまたは前のセルでコードを実行中に、カーネルがクラッシュしました。エラーの原因を特定するには、セル内のコードを確認してください。詳細については、<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a> をクリックしてください。さらなる詳細については、Jupyter [log] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "model_name = \"csebuetnlp/mT5_m2m_crossSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=['道内各地の百貨店や商業施設で２日、初売りが行われ、大勢の人たちが新春の買い物を楽しんだ。札幌市中央区の丸井今井札幌本店では約４千人の行列ができた。丸井今井札幌は福袋約２万６千点を用意。午前５時半ごろから買い物客が並び、予定を１５分早めて８時４５分に初売りを始めた。地下２階は有名菓子の福袋を求める人で混み合った。札幌丸井三越の担当者は「食品の福袋は人気が高まっていて、並んで何種類も買うお客さまが多い」と話す。４階の婦人服売り場も人気で、夕張市から訪れた看護教員の武内裕美子さん（３６）は友人とブランド品福袋を購入。「並ぶため午前４時に家を出た。買えたので年始めからうれしい気分です」と笑顔だった。札幌では札幌三越、さっぽろ東急百貨店、大丸札幌店、ＪＲタワーなどもそろって２日に初売り。道内では帯広市の百貨店藤丸、函館市の丸井今井函館店などの百貨店や大型店が初売りを行った。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model, tokenizer)\n",
    "shap_values = explainer(s)\n",
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
